{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This week is about two topics. Decision trees and clustering. The main exercise will be on decision trees, and we'll also talk a bit about unbalanced data sets as well as a little exercise on clustering, an example of unsupervised learning. Before we get started, we'll talk about workload, however. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Discussing the course workload\n",
    "\n",
    "Last week we talked about what could be better with the class and some of you guys mentioned that parts of the class are a lot of work. So this week we'll start an investigtion of that. Below, I'm including a Google form to collect some data on the matter. I ask a few additional questions because I want to understand how your background plays influences the answers. \n",
    "\n",
    "I'll do an analysis of your answers and tell you about the findings next week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"400\"\n",
       "            src=\"https://docs.google.com/forms/d/1VsgNpMMQk-sZoZD2pxeXmKFXfnhZ0EGwvQ3YDNZbGwA/viewform?embedded=true\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1051059d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame, YouTubeVideo\n",
    "IFrame(\"https://docs.google.com/forms/d/1VsgNpMMQk-sZoZD2pxeXmKFXfnhZ0EGwvQ3YDNZbGwA/viewform?embedded=true\", \n",
    "       width=600, height=400)\n",
    "\n",
    "# I'm not showing the entire questionnaire in the iframe below, but you should be able to scroll within the frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Decision trees (DSFS Chapter 17)\n",
    "\n",
    "> _Reading I_: The visual introduction to decision trees on [**this webpage**](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/\n",
    ") is AMAZING. Take a look to get an intuitive feel for how trees work. Do not miss this one, it's a treat!\n",
    "\n",
    "---\n",
    "\n",
    "> _Reading II_: DSFS Chapter 17. Work through chapter 17 of the book. It's not as flashy as the fancy `D3.js` based web-explanation, but it's very good (in my humble opinion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"338\"\n",
       "            src=\"https://www.youtube.com/embed/LAA_CnkAEx8\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x1051057d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ole explains decision trees\n",
    "YouTubeVideo(\"LAA_CnkAEx8\",width=600, height=338)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> _Exercises_: Just a few questions to make sure you've read the text and/or watched the video.\n",
    ">\n",
    "> * There are two main kinds of decision trees depending on the type of output (numeric vs. categorical). What are they?\n",
    "> * Explain in your own words: Why is _entropy_ useful when deciding where to split the data?\n",
    "> * Why are trees prone to [overfitting](https://www.youtube.com/watch?v=DQWI1kvmwRg)?\n",
    "> * Explain (in your own words) how random forests help prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chief Suneman arrives at work one day and immediately starts motivating the team by randomly yelling at everyone in order to increase morale - something like [this](https://www.youtube.com/watch?v=L_QCioSGgwU). After a while, the team gets him calmed down with a cup of coffee and a movie. It doesn't help, after watching the first 10 minutes (see below) he comes out of his office with an outrageous request for the newly appointed data science team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/BmSarhudhiY\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x105105890>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YouTubeVideo(\"BmSarhudhiY\",width=600, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chief wants you to start from real data and build a system that replicates the functionality in the _Minority Report_ system. Imagine, we find out that certain type of crime is going to take place - as well as the exact time of the crime - **but that we don't know _where_**, then Suneman wants an algorithm that will predict which district the crime is most likely to take place in. Specifically, let's build an algorithm that predicts the location of a crime based on its type and time.\n",
    "\n",
    "The friendly leader of the data-science team, Captain Mones, helps break down the task.\n",
    "\n",
    "> _Exercise_: Building the _minority report_ algorithm\n",
    ">\n",
    "> * Use the category of the crimes to build a decision tree that predicts the corresponding district. You can implement the ID3 tree in the DSFS book, or use the [`DecisionTreeClassifier`](http://scikit-learn.org/stable/modules/tree.html) class in scikit-learn. For training, you can use 90% of the data and test the tree prediction on the remaining 10%. \n",
    ">  - What is the fraction of correct predictions? \n",
    ">  - What are the correct predictions if you restrict the training/prediction to single districts (for example, predicting Mission vs. all other districts, etc)? \n",
    ">   - Compare it to the random guess, what would you get if you'd guess a district randomly? \n",
    ">   - And if you'd guess always one of the districts (for example the district with the most crimes)?\n",
    "> * Now, add the day of the week to the features, do any of the the performance measures improve? \n",
    "> * Let's try some examples to see if the algorithm is working. \n",
    ">  - There is a new crime (prositution) on Monday 10pm. What are the three most likely districts? \n",
    ">  - Also find the most likely districts for a gambling on Wednesday 1pm. \n",
    ">  - And also try out an arson case on Sunday 7am?\n",
    "> * Visualize the tree so that you can see what it actually does! For visualization, you can use the export_graphviz method of `scikit-learn` and then convert the `.dot` file to a PDF. \n",
    ">   - Note: [in order to use GraphViz in IPython, you need to install it on your system first](http://www.graphviz.org/Download..php)!\n",
    "> * As you might see in the visualization, the tree runs out of possible feature values to check before refining the decision. Try increasing the number of features: add part of the day (`night`=0-5, `morning`=6-10, `midday`=11-14, `afternoon`=15-17, `evening`=18-23). Is it better? What happens if you don't break the day into parts but use raw hour values?\n",
    "> * It's unlikely that the classifier overfits in our case. Explain why. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digression: Decision trees and unbalanced data\n",
    "\n",
    "An important problem in many data-science problems is _unbalanced data_. We consider a dataset balanced when the categories we care about have about equal size (e.g. if we want to predict the gender of individuals in the general population). When the category size are imbalanced (e.g. if we are looking for people with a rare disease such as _leukemia_ in the general population), many machine learning algorithms can have problems.\n",
    "\n",
    "> _Reading_: [This article](http://arstechnica.co.uk/security/2016/02/the-nsas-skynet-program-may-be-killing-thousands-of-innocent-people/) does a great job of explaining the problem.\n",
    "\n",
    "---\n",
    "\n",
    "> _Exercises_: I know you read the article above, but just a few questions to make you reflect on the details of the story.\n",
    "> \n",
    "> * Explain what features go into the terrorist detection model\n",
    "> * Which algorithm is used to detect the terrorists?\n",
    "> * Do you agree with the algorithm that Al-Jazeera bureau chief is a good target? Justify your answer.\n",
    "> * What's the size of the training set?\n",
    "> * Why is it still a problem that the algorithm has a false alam rate at 0.18% at a 50% miss rate?\n",
    "> * Do you have a better grasp of the problems with overfitting after reading this article?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Clustering (DSFS Chapter 19)\n",
    "\n",
    "Clustering is an important _unsupervised_ method to reveal structure in the data. You've already done a lot of hard work today, so let's make this one as easy as possible.\n",
    "\n",
    "> _Reading_: Check out chapter 19 of DSFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"338\"\n",
       "            src=\"https://www.youtube.com/embed/G7jYVrCVygU\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x105105690>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ole talks about clustering\n",
    "YouTubeVideo(\"G7jYVrCVygU\",width=600, height=338)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this exercise we explore $K$-means clustering - and we it out on the locations of the `PROSTITUTION` crime type. Applying a clustering method makes sense because we know from our earlier work that this crime type tends to happen in only a few locations. We'll also talk a little bit about model selection and [overfitting](https://www.youtube.com/watch?v=DQWI1kvmwRg) in unsupervised models.\n",
    "\n",
    "> _Exercise_: $K$-means\n",
    "> \n",
    "> * Visualize the prostitution data (e.g. by plotting it on a map)\n",
    "> * Train models of $K = 2,\\ldots,10$ on the prostitution data.\n",
    "> * Explore how the total squared error changes as a function of $K$ and identify what you think is the right number of clusers based on the knee-point in the squared error plot.\n",
    "> * And by the way: The fit only gets better when we add more means - why not keep adding more of them: Explain in your own words why it makes sense to stop around a knee-point.\n",
    "> * Another way of estimating the right number of clusters in a $K$-means problem is _stability analysis_. The idea is the following\n",
    ">   - For each $K = 2,\\ldots,10$ generate $N = 10$ clusterings based on random 50% of data (or some other fraction of data/bootstrap).\n",
    ">   - Calculate the pairwise similarity between the clusterings. \n",
    ">   - We now define _stability_ for some value of $K$ as average pairwise similarity of the $N$ clustering, where the similarity is the cosine distance $\\frac{\\mathbf{c}_i^K\\cdot\\mathbf{c}_j^K}{||\\mathbf{c}_i^K||\\,||\\mathbf{c}_j^K||}$ between centroid vectors $\\mathbf{c}_i^K$ and $\\mathbf{c}_j^K$.\n",
    ">   - We now say that the right $K$ maximizes stability.\n",
    "> * Explain why stability should help you find the right number of clusters.\n",
    "> * **Optional**: Perform stability analysis on the prostitution data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
