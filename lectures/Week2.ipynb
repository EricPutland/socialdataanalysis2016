{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2\n",
    "\n",
    "## Overview\n",
    "\n",
    "Ok, so we've made it to week 2. Today we'll be working through Chapters 4,5,6,7 (and 8) in _Data Science from Scratch_. This is all stuff that you should know about - but since we're doing everything from scratch this semester, I think it's good to refresh those topics. \n",
    "\n",
    "We'll have a couple of exercises for each chapter - some will just require you to write down some thoughts on paper, others will require some calculations.\n",
    "\n",
    "In addition to this, we'll also practice plotting a bit more (this is a course on data visualization after all), and I'll start the whole thing off with some practical information.\n",
    "\n",
    "But we'll start things off with some practical information :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Some practical things\n",
    "\n",
    "The videos below contain important practical information, so I _highly_ recommend you watch them. You don't necessarily have to start by watching these - it's something you can do if you need a break from coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Video 1. The structure of the course (screencast)\n",
    "# - home page\n",
    "# - where you can find information (grading, books, etc)\n",
    "# - course structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Video 2: The assignments (screencast)\n",
    "# - Assignment 1 & 2\n",
    "# - Project Assignment A\n",
    "# - Project Assignment B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Video 3. Peer grading (actual video)\n",
    "# - The problem. Feedback is impossible in a large course\n",
    "# - The solution. Peergrade.io.\n",
    "#  - You'll get great feedback, and you'll be qualified to give feedback\n",
    "#  - You'll get smarter. Providing feedback actually accellerates your learning. \n",
    "#  - It's more work, but you'll get credit for it. Good feedback is rewarded - bad feedback is punished.\n",
    "#  - How does that work. Feedback on feedback (even on TA evaluations).\n",
    "#  - It's all anonymous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Statistics (DSFS Chapter 5)\n",
    "\n",
    "> _Reading_. Let's get cracking. Pick up DSFS and\n",
    "> \n",
    "> * Read chapter 4\\.\n",
    "> * Read chapter 5\\.\n",
    "> \n",
    "\n",
    "Well, Chapter 4 is so basic that I think we can safely skip any exercises related to it. And I really think you should use `numpy` rather than use the functions from the book. \n",
    "\n",
    "Chapter 5 on statistics, however, is a lot more interesting for us. The lessons here will be important throughout the course, so this is a good place for us to start the exercises. We start with some simple questions about the text. **Don't forget that you should be answering all exercises in an IPython notebook.**\n",
    "\n",
    "> _Exercises_: Chapter 5 (just some questions from the text)\n",
    ">\n",
    "> * _Mean and median_: Explain the difference between the mean and the median in your own words. In what kinds of dataset are the mean and median similar? Can you think of a dataset where the mean and median would be very different?\n",
    "> * _Variance_: Explain the variance in your own words.\n",
    "> * _A paradox_: What is Simpson's Paradox. Provide your own example of a dataset where this issue occurs.\n",
    "> * _Correlation and causation_: Explain what's funny about [**this comic**](https://xkcd.com/552/).\n",
    "\n",
    "In my mind, statistics and visualization are intimately connected. If we plot data, we can usually learn a lot about the underlying statistics - sometimes things that are difficult to discern based on even quite sophisticated measures. Today's first Exercise illustrates this point.\n",
    "\n",
    "> _Exercise_: Chapter 5 (beyond the book)\n",
    "> \n",
    "> Start by downloading these four datasets: [Data 1](https://dl.dropboxusercontent.com/u/153071/teaching/02806_2016/data1.tsv), [Data 2](https://dl.dropboxusercontent.com/u/153071/teaching/02806_2016/data2.tsv), [Data 3](https://dl.dropboxusercontent.com/u/153071/teaching/02806_2016/data3.tsv), and [Data 4](https://dl.dropboxusercontent.com/u/153071/teaching/02806_2016/data4.tsv). The format is `.tsv`, which stands for _tab separated values_. \n",
    "> Each file has two columns (separated using the tab character). The first column is $x$-values, and the second column is $y$-values.  \n",
    ">\n",
    "> It's ok to just download these files to disk by right-clicking on each one, but if you use Python and _urllib_ or _urllib2_ to get them, I'll really be impressed. If you don't know how to do that, I recommend opening up Google and typing \"download file using Python\" or something like that. When interpreting the search results remember that _stackoverflow_ is your friend.\n",
    "> \n",
    "> * Using the `numpy` function `mean`, calculate the mean of both $x$-values and $y$-values for each dataset. \n",
    "> * Use python string formatting to print precisely two decimal places of these results to the output cell. Check out [this _stackoverflow_ page](http://stackoverflow.com/questions/8885663/how-to-format-a-floating-number-to-fixed-width-in-python) for help with the string formatting. \n",
    "> * Now calculate the variance for all of the various sets of $x$- and $y$-values (to three decimal places).\n",
    "> * Use `numpy` to calculate the [Pearson correlation](https://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient) between $x$- and $y$-values for all four data sets (also to three decimal places).\n",
    "> * The next step is use _linear regression_ to fit a straight line $f(x) = a x + b$ through each dataset and report $a$ and $b$ (to two decimal places). An easy way to fit a straight line in Python is using `scipy`'s `linregress`. It works like this\n",
    "> ```\n",
    "> from scipy import stats\n",
    "> slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    ">```\n",
    "> * Finally, it's time to plot the four datasets using `matplotlib.pyplot`. Use a two-by-two [`subplot`](http://matplotlib.org/examples/pylab_examples/subplot_demo.html) to put all of the plots nicely in a grid and use the same $x$ and $y$ range for all four plots. And include the linear fit in all four plots. (To get a sense of what I think the plot should look like, you can take a look at my version [here](https://dl.dropboxusercontent.com/u/153071/teaching/02806_2016/anscombe.png).)\n",
    "> * Explain - in your own words - what you think my point with this exercise is.\n",
    "\n",
    "\n",
    "Get more insight in the ideas behind this exercise by reading [here](https://en.wikipedia.org/wiki/Anscombe%27s_quartet)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Probability  (DSFS Chapter 6)\n",
    "\n",
    "> _Reading_: You guessed it! Have a look at DSFS Chapter 6.\n",
    "\n",
    "Probability theory is another one of those topics that we'll glide past gently (since you probably remember everyting about if from another class), but we'll do a couple of fun ones just to\n",
    "\n",
    "> _Exercise_: Conditional probability and having children.\n",
    ">\n",
    "> There's a nice example in the book where Joel illustrates the conditional probablity of “both children are girls” conditional on the event “at least one of the children is a girl” versus the probability that \"both children are girls\" knowing \"the older sister is a girl\" using the little code-snippet reproduced below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(both | older): 0.514228456914\n",
      "P(both | either):  0.341541328364\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from __future__ import division\n",
    "\n",
    "def random_kid():\n",
    "    return random.choice([\"boy\", \"girl\"])\n",
    "\n",
    "both_girls = 0\n",
    "older_girl = 0\n",
    "either_girl = 0\n",
    "\n",
    "random.seed(0)\n",
    "for _ in range(10000):\n",
    "    younger = random_kid() \n",
    "    older = random_kid() \n",
    "    \n",
    "    if older == \"girl\":\n",
    "        older_girl += 1\n",
    "    if older == \"girl\" and younger == \"girl\":\n",
    "        both_girls += 1\n",
    "    if older == \"girl\" or younger == \"girl\":\n",
    "        either_girl += 1\n",
    "\n",
    "print \"P(both | older):\", both_girls / older_girl # 0.514 ~ 1/2 \n",
    "print \"P(both | either): \", both_girls / either_girl # 0.342 ~ 1/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's imagine a new family with three children. Assuming that each child is equally likely to be a boy or a girl, and that the gender of each subsequent child is independent of the gender its older siblings. Use Python code to answer the following questions.\n",
    "> * What is the probability of three girls?\n",
    "> * What is the probability of two girls and one boy?\n",
    "> * What is the probability of one girl and two boys?\n",
    "> * What is the probability of three boys?\n",
    "> * What is the probability that all children are girls given that the oldest child is a girl?\n",
    "> * What is the probability that all children are girls given that one of the children is a girl?  \n",
    "> * Work out the expected answer using your math skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> _Exercise_: Central limit theorem \n",
    "\n",
    ">The central limit theorem is fun because we can get Gaussian distributions from probability distributions that are _not_ Gaussian. Let's explore that in the following exercise.\n",
    "\n",
    "> * Use Python's `random` module to simulate rolling a fair six-sided die 10 000 000 times.\n",
    "> * Plot the distribution of dice rolls using a bar-chart. _Hint_: Use `counter` (see p. 24) to bin the values, then go back to Chapter 3 for examples of how to plot bar-charts (or try Google $\\rightarrow$ _stackoverflow_).\n",
    "> * Describe the shape of the distribution.\n",
    "> * Now perform a new simulation. Roll a fair six-sided die 10 times and take the _average_. Do that 1 000 000 times.\n",
    "> * Plot the distribution of those average values. This time you can't use `counter` (since the averages are not integer values). \n",
    ">  * Instead use `numpy.histogram` to bin those number into 25 bins. \n",
    ">  * What does the `numpy.histogram` function return? Do the two arrays have the same length?\n",
    ">  * Then let's use `matplotlib.pyplot.bar` to plot the binned data. You will have to deal with the fact that the counts- and bin-arrays have different lengths. Explain how you deal with this problem and why.\n",
    "> * Describe the shape of _this_ distribution. Explain in your own words what happened to that flat distribution of die-rolls to suddenly make it Gaussian just by taking some averages.\n",
    "> * Calculate the mean $\\mu$ and standard deviation $\\sigma_{\\textrm{observed}}$ of the averaged values. Could you have predicted these values by reading DSFS pp. 78-80?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Hypothesis and inference  (DSFS Chapter 7)\n",
    "\n",
    "> _Reading_: Take a look at DSFS Chapter 7. Maybe also just skim Chapter 8 to get a sense of what's going on.  \n",
    "\n",
    "There's a lot going on in Chapter 7, enough for an entire course really, but my guess is that you guys are already getting tired, so the job is just to read through and get a sense of what's going on. In particular, I recommend taking a close look at the cental example about testing the fairness of a coin. That example nicely captures the cental concepts.\n",
    "\n",
    "We'll return to the topic of inferencel later when we have an exercise that illustrates some of the concepts. For now, just a couple of questions to show that you've looked at the text.\n",
    "\n",
    "> _Exercises_: Did you read the text?\n",
    ">\n",
    "> * What's the null hypothesis when testing if a coin is fair?\n",
    "> * Explain in your own words what Joel means by _significance_ on p. 83.\n",
    "> * Explain in your own words what Joel means by _power_ on p. 83.\n",
    "> * Write down a short definition of $p$-value.\n",
    "> * Explain the problem with $p$-hacking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
